{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LK2022_Code_Submission.ipynb","provenance":[],"collapsed_sections":["dTQxqAqK4teB","dXAyohSrA3KF"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# This Notebook is designed to work on Google Colab"],"metadata":{"id":"Z7x-CgO_ixJy"}},{"cell_type":"markdown","source":["# Config"],"metadata":{"id":"dTQxqAqK4teB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHkBgzILuatW"},"outputs":[],"source":["# Installing the required libraries and datasets\n","!git clone https://gitlab.com/bigirqu/quranqa.git\n","!git clone https://github.com/aub-mind/arabert.git\n","!pip install farasapy\n","!pip install simpletransformers"]},{"cell_type":"code","source":["# Simple Transformers need to be installed again to avoid issues with restarting the kernel\n","# Also, weneed to set the setuptools to this version to be compatibale with PyTorch and Simple Transformers\n","!pip install simpletransformers\n","!pip install setuptools==57.4.0"],"metadata":{"id":"uTPTdsEf9Ayk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the required libraries and packages\n","# Instatiate the Farasa Segmenter and assign the model name and trype for Simple Transformers\n","\n","from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs\n","import torch\n","import json, argparse\n","from collections import Counter\n","import re\n","import string\n","import logging\n","import os\n","import numpy as np\n","import pandas as pd\n","from farasa.segmenter import FarasaSegmenter\n","farasa_segmenter = FarasaSegmenter()\n","model_name = 'aubmindlab/bert-large-arabertv02'\n","model_type = 'bert'\n"],"metadata":{"id":"d2a0v40fzzPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here are the functions from the Qur'an QA scripts\n","# Please note that we changed the PassageQuestion class to be compatible with Simple Transformers format\n","# Please note that we changed the function of dump_jsonl to accommodate the answers to be in dictionaries and save it in json format that is compatible with the shared-task requirement.\n","\n","def load_jsonl(input_path) -> list:\n","    \"\"\"\n","    Read list of objects from a JSON lines file.\n","    \"\"\"\n","    data = []\n","    with open(input_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            data.append(json.loads(line.rstrip('\\n|\\r')))\n","    print('Loaded {} records from {}'.format(len(data), input_path))\n","    return data\n","\n","def dump_jsonl(data, output_path, append=False):\n","    \"\"\"\n","    Write list of objects to a JSON lines file.\n","    \"\"\"\n","    mode = 'a+' if append else 'w'\n","    with open(output_path, mode, encoding='utf-8') as f:\n","        for line in data:\n","            json_record = json.dumps({line:data[line]}, ensure_ascii=False)\n","            # json_record.replace(\"{\",\"\",1)\n","            # json_record[0] == \"#\"\n","            # re.sub(\"\")\n","            # print(type(json_record[0]))\n","            s = list(json_record)\n","            s[0] = ''\n","            s[-1] = ','\n","            json_record = \"\".join(s)\n","            f.write(json_record + '\\n')\n","    print('Wrote {} records to {}'.format(len(data), output_path))\n","\n","\n","\n","class PassageQuestion():\n","    def __init__(self,dictionary) -> None:\n","        self.pq_id = None\n","        self.passage = None\n","        self.surah = None\n","        self.verses = None\n","        self.question = None\n","        self.answers = []\n","        self.pq_id = dictionary[\"pq_id\"]\n","        self.passage = dictionary[\"passage\"]\n","        self.surah = dictionary[\"surah\"]\n","        self.verses = dictionary[\"verses\"]\n","        self.question = dictionary[\"question\"]\n","        for answer in dictionary[\"answers\"]:\n","            self.answers.append(Answer(answer))\n","\n","    def to_dict(self) -> dict:\n","        passge_question_dict = {\n","        \"context\":self.passage,\n","        \"qas\": [{\n","        \"id\":self.pq_id,\n","        \"surah\":self.surah,\n","        \"verses\":self.verses,\n","        \"question\":self.question,\n","        \"answers\":[x.to_dict() for x in self.answers]}]\n","        }\n","        return passge_question_dict\n","\n","class Answer():\n","    def __init__(self,dictionary) -> None:\n","        self.text = dictionary[\"text\"]\n","        self.start_char = dictionary[\"start_char\"]\n","\n","    def to_dict(self) -> dict:\n","        answer_dict = {\n","        \"text\":self.text,\n","        \"answer_start\":self.start_char\n","        }\n","        return answer_dict\n","\n","\n","def read_JSONL_file(file_path) -> list:\n","    data_in_file = load_jsonl(file_path)\n","\n","    # get list of PassageQuestion objects\n","    passage_question_objects = []\n","    for passage_question_dict in data_in_file:\n","        # instantiate a PassageQuestion object\n","        pq_object = PassageQuestion(passage_question_dict)\n","        passage_question_objects.append(pq_object)\n","\n","    print(f\"Collected {len(passage_question_objects)} Object from {file_path}\")\n","    return passage_question_objects\n","\n"],"metadata":{"id":"Vinukmzs3SEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking the Google Colab using cuda instead of cpu.\n","\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","    !nvidia-smi\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"8m3bNTrg-lYj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Opening the files"],"metadata":{"id":"dXAyohSrA3KF"}},{"cell_type":"code","source":["# Loading the files and assign them to variables\n","\n","train = load_jsonl(\"/content/quranqa/datasets/qrcd_v1.1_train.jsonl\")\n","dev = load_jsonl(\"/content/quranqa/datasets/qrcd_v1.1_dev.jsonl\")\n","test = load_jsonl(\"/content/quranqa/datasets/qrcd_v1.1_test_noAnswers.jsonl\")"],"metadata":{"id":"BkSGB7bx0ebR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = []\n","for item_dict in np.arange(0,len(train)):\n","    change_items = PassageQuestion(train[item_dict])\n","    final_change = change_items.to_dict()\n","    train_data.append(final_change)"],"metadata":{"id":"fYSIEMTfw6vh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_data = []\n","for item_dict in np.arange(0,len(dev)):\n","    change_items = PassageQuestion(dev[item_dict])\n","    final_change = change_items.to_dict()\n","    dev_data.append(final_change)"],"metadata":{"id":"MkcGBp5FxEMO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = []\n","for item_dict in np.arange(0,len(test)):\n","    change_items = PassageQuestion(test[item_dict])\n","    final_change = change_items.to_dict()\n","    test_data.append(final_change)"],"metadata":{"id":"577xcq83mejZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Simple Transformers parameters and instatiate the model"],"metadata":{"id":"AIygX1yQObtg"}},{"cell_type":"code","source":["# Set the model's arguments/parameters for the training\n","models_args = QuestionAnsweringArgs()\n","models_args.train_batch_size = 15\n","models_args.evaluate_during_training = True\n","models_args.n_best_size = 5\n","models_args.save_model_every_epoch = False\n","models_args.save_steps = -1\n","models_args.learning_rate = 0.0001\n","models_args.num_train_epochs = 5\n","models_args.manual_seed = 109\n","models_args.output_dir = \"/content/output/\""],"metadata":{"id":"bxVonZo5OvhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instatiate the model and set the \"args\" to model_args variable\n","model = QuestionAnsweringModel(\n","    model_type, model_name, args= models_args\n",")"],"metadata":{"id":"sMM5YuVZRCrt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training the model and predicting the results"],"metadata":{"id":"R4iZD8aFfVI9"}},{"cell_type":"code","source":["model.train_model(train_data=train_data, eval_data = dev_data)"],"metadata":{"id":"CAIeoSuFRZXb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result, texts = model.predict(test_data, n_best_size=5)"],"metadata":{"id":"A4yVTgVT12FD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preparing the run file"],"metadata":{"id":"RIMkrOOqhq7j"}},{"cell_type":"code","source":["# Create the dictionary to combine the answers and their probability scores\n","# If the list has more than 1 answer, then consider the ranks from 1 till the end of the loop\n","# Else let the rank be just 1\n","\n","submit_test_dict = {}\n","\n","for n,z in zip(result, texts):\n","  \n","  temp_list = []\n","  if len(n['answer']) > 1:\n","    rank = 1\n","    for m,y in zip(n['answer'], z['probability']):\n","      temp_dict = {}\n","      temp_dict.update({\n","          'answer': m,\n","          'rank': rank,\n","          'score': y\n","      })\n","      temp_list.append(temp_dict)\n","      rank = rank + 1\n","    \n","    submit_test_dict.update({\n","        n['id']: temp_list\n","    })\n","  \n","  else:\n","    for m,y in zip(n['answer'], z['probability']):\n","      temp_dict = {}\n","      temp_dict.update({\n","          'answer': m,\n","          'rank': 1,\n","          'score': y\n","      })\n","      temp_list.append(temp_dict)\n","    \n","    submit_test_dict.update({\n","        n['id']: temp_list\n","    })\n","  \n"],"metadata":{"id":"Q1GcZpP8RepO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check of the length of the created dictionary equals the test set\n","len(submit_test_dict) == len(test_data)"],"metadata":{"id":"eNCc-58v8oRX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count and remove the empty answers except if the empty answer is the only one to avoid the error in the evaluation script.\n","count = 0\n","for id_key in submit_test_dict:\n","  for i, small_D in enumerate(submit_test_dict[id_key]):\n","    if len(submit_test_dict[id_key]) > 1 and small_D['answer'] == '':\n","      \n","      count += 1\n","      submit_test_dict[id_key].remove(small_D)\n","    \n","    elif len(submit_test_dict[id_key]) > 1 and small_D['answer'] == 'empty':\n","\n","      count += 1\n","      submit_test_dict[id_key].remove(small_D)\n","\n"," \n","for id_key in submit_test_dict:\n","  c = 1\n","  for i, small_D in enumerate(submit_test_dict[id_key]):\n","    small_D['rank'] = c \n","    c += 1\n","  \n","count"],"metadata":{"id":"Kx8NRLI91yZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Write and save the file in json format\n","dump_jsonl(submit_test_dict, \"LK2022_run21.json\")"],"metadata":{"id":"FzvW2VoZKtot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Now, please consider the following prior running the file on the submission checker script:\n","- Open the json file, and \n","- add the opening curly bracket \"{\" at the beginning of the file, and \n","- remove the comma \",\" at the end of the file, and\n","- add a closing curly bracket \"}\" at the end of the file."],"metadata":{"id":"AQHMNKTjgu0N"}},{"cell_type":"markdown","source":["# Run the file on the submission check script"],"metadata":{"id":"77gFA-2FE8O-"}},{"cell_type":"code","source":["!python /content/quranqa/code/quranqa22_submission_checker.py --run_file \"/content/LK2022_run21.json\""],"metadata":{"id":"mycVxkI9Wf56"},"execution_count":null,"outputs":[]}]}